## Exercises
<br />

Your company decided that they will use AWS as a cloud provider to deploy their applications. It's too much overhead to manage multiple platforms, including the billing etc.

So you need to deploy the previous NodeJS application on an EC2 instance now. This means you need to create and prepare an EC2 server with the AWS Command Line Tool to run your NodeJS app container on it.

You know there are many steps to set this up, so you go through it with step by step exercises.

<details>
<summary>Exercise 1: Create IAM user</summary>
<br />

**Tasks:**

First of all, you need an IAM user with correct permissions to execute the tasks below.
- Create a new IAM user "your name" with "devops" user-group
- Give the "devops" group all needed permissions to execute the tasks below - with login and CLI credentials

Note: Do that using the AWS UI with Admin User

**Steps to solve the tasks:**

**Step 1:** Create a new user
- Open the browser and navigate to the [AWS Login Page](https://eu-north-1.signin.aws.amazon.com). Login as root user or, if already available, as admin user.
- Open the "Services" dialog (link on the top left), click the filter "All services" and select "Security, Identity & Compliance" > "IAM" > "Access Management" > "Users".
- Press the "Add users" button and enter the username 'fesi'.
- Check the optional "Provide user access to the AWS Management Console" checkbox. Select the radio buttons "I want to create an IAM user" and "Autogenerated password". Check "Users must create a new password at next sign-in" as recommended. Press the "Next" button.
- Choose "Add user to group" and press the "Create group" button in the section below.
- Enter the usergroup name 'devops'.
- Enter 'EC2Full' in the search field of the "Permissions policies" section below and select the permission "AmazonEC2FullAccess".
- Enter 'VPCFull' in the search field of the "Permissions policies" section below and select the permission "AmazonVPCFullAccess".
- Press the "Create user group" button at the bottom.
- Check the new "devops" user group in the "User groups" section and press the "Next" button.
- On the "Review and create" page press "Create user".
- Download the .csv file containing the login URL and credentials by pressing the "Download .csv file" button.

**Step 2:** Change password
- Logout as root/admin user.
- Login again as the new 'fesi' user. The sign-in URL and the initial password can be found in the downloaded .csv file.
- Change the initial password.
- Logout.

**Step 3:** Generate a secret access key
- Login again as root / admin.
- Go to the users list, click on the new 'fesi' user
- Select the "Security credentials" tab, scroll down to "Access keys" and press the "Create access key" button.
- Select "Command line interface (CLI)" and check the "I understand the above recommendation and want to proceed to create an access key" checkbox.
- Press "Next". Press "Create access key".
- On the "Retrieve access keys" page press the "Download the .csv file" button.
- Press "Done".

</details>

******

<details>
<summary>Exercise 2: Configure AWS CLI</summary>
<br />

**Tasks:**

You want to use the AWS CLI for the following tasks. So, to be able to interact with the AWS account from the AWS Command Line tool you need to configure it correctly:
- Set credentials for that user for AWS CLI
- Configure correct region for your AWS CLI

**Steps to solve the tasks:**

**Step 1:** Configure AWS CLI
```sh
aws configure
  AWS Access Key ID [None]: ****************LRGA # downloaded when creating the secret access key for 'fesi' user
  AWS Secret Access Key [None]: ************PQHr # downloaded when creating the secret access key for 'fesi' user
  Default region name [None]: eu-central-1 # Frankfurt
  Default output format [None]: json
```

</details>

******

<details>
<summary>Exercise 3: Create VPC</summary>
<br />

**Tasks:**

You want to create the EC2 Instance in a dedicated VPC, instead of using the default one. So you:
- create a new VPC with 1 subnet and
- create a security group in the VPC that will allow you access on ssh port 22 and will allow browser access to your Node application (using the AWS CLI)

**Steps to solve the tasks:**\
**Step 1:** Create a new VPC with one subnet
```sh
# create VPC
aws ec2 create-vpc \
  --cidr-block 10.0.0.0/24 \
  --query Vpc.VpcId \
  --output text
# => vpc-0d6389f901133c5b2

# create subnet in the VPC
aws ec2 create-subnet \
  --vpc-id vpc-0d6389f901133c5b2 \
  --cidr-block 10.0.0.32/28 \
  --availability-zone eu-central-1a \
  --query Subnet.SubnetId \
  --output text
# => subnet-08b0b65a552e2347a

# subnets of non default VPCs do not automatically assign a public IP address when launching EC2 instances
# we modify the subnet accordingly (alternatively we can add the --associate-public-ip-address option to the
# 'aws ec2 run-instances' command)
aws ec2 modify-subnet-attribute \
  --map-public-ip-on-launch \
  --subnet-id subnet-08b0b65a552e2347a
```

**Step 2:** Make the subnet public
```sh
# create internet gateway
aws ec2 create-internet-gateway \
  --query InternetGateway.InternetGatewayId \
  --output text
# => igw-0ae928c4a3842e5d5

# attach internet gateway to VPC
aws ec2 attach-internet-gateway \
  --vpc-id vpc-0d6389f901133c5b2 \
  --internet-gateway-id igw-0ae928c4a3842e5d5

# create a custom route table for the VPC
aws ec2 create-route-table \
  --vpc-id vpc-0d6389f901133c5b2 \
  --query RouteTable.RouteTableId \
  --output text
# => rtb-097d90cafaabb0005

# create route rule for handling all traffic between internet & VPC
aws ec2 create-route \
  --route-table-id rtb-097d90cafaabb0005 \
  --destination-cidr-block 0.0.0.0/0 \
  --gateway-id igw-0ae928c4a3842e5d5

# associate subnet with the route table to allow internet traffic in the subnet as well
aws ec2 associate-route-table \
  --route-table-id rtb-097d90cafaabb0005 \
  --subnet-id subnet-08b0b65a552e2347a
```

**Step 3:** Create security group in the VPC to allow access on port 22
```sh
# create security group
aws ec2 create-security-group \
  --group-name ssh-access \
  --description "Security group for SSH access" \
  --vpc-id vpc-0d6389f901133c5b2 \
  --query GroupId \
  --output text
# => sg-0a6a9345d15c51f5e

# add incoming access on port 22 from my IP address to security group
aws ec2 authorize-security-group-ingress \
  --group-id sg-0a6a9345d15c51f5e \
  --protocol tcp \
  --port 22 \
  --cidr 31.10.151.3/32
```

</details>

******

<details>
<summary>Exercise 4: Create EC2 Instance</summary>
<br />

**Tasks:**

Once the VPC is created, you:
- Create an EC2 instance in that VPC
- with the security group you just created and ssh key file (using the AWS CLI)

**Steps to solve the tasks:**\
**Step 1:** Create an SSH key pair
```sh
# create key pair, save it locally in .pem file
aws ec2 create-key-pair \
  --key-name WebServerKeyPair \
  --query "KeyMaterial" \
  --output text > WebServerKeyPair.pem

# set stricter permission on on .pem file
chmod 400 WebServerKeyPair.pem
```

**Step 2:** Create an EC2 instance in our subnet
```sh
# create an EC2 instance with the above key, in our subnet and using the security group we created
aws ec2 run-instances \
  --image-id ami-0fa03365cde71e0ab \
  --count 1 \
  --instance-type t2.micro \
  --key-name WebServerKeyPair \
  --security-group-ids sg-0a6a9345d15c51f5e \
  --subnet-id subnet-08b0b65a552e2347a \
  --associate-public-ip-address \
  --query "Instances[].InstanceId" \
  --output text
# => i-0ff44d9f8f07fea75

# validate that EC2 instance is in a running state, and get its public ip address to connect via ssh
aws ec2 describe-instances \
  --instance-id i-0ff44d9f8f07fea75 \
  --query "Reservations[].Instances[].{State:State.Name,Address:PublicIpAddress}"
# => {
#        "State": "running",
#        "Address": "3.122.205.189"
#    }
```

</details>

******

<details>
<summary>Exercise 5: SSH into the server and install Docker and Docker-Compose on it</summary>
<br />

**Tasks:**

Once the EC2 instance is created successfully, you want to prepare the server to run Docker containers. So you:
- ssh into the server and
- install Docker and Docker-Compose on it to run the dockerized application later

**Steps to solve the tasks:**\
**Step 1:** SSH into EC2
```sh
ssh -i WebServerKeyPair.pem ec2-user@3.122.205.189
```

**Step 2:** Install Docker
```sh
# install Docker
sudo yum update -y
sudo yum install -y docker

# start docker service
sudo systemctl start docker 

# allow ec2-user to run docker commands without sudo by adding it to docker group
sudo usermod -aG docker ec2-user

# install docker compose
sudo curl -SL https://github.com/docker/compose/releases/download/v2.17.2/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose

sudo chmod +x /usr/local/bin/docker-compose

# test the installation
docker-compose --version
```

</details>

******

### Set up Continuous Deployment

Now you don't want to deploy manually to the server all the time, because it's time-consuming and also sometimes you miss it, when changes are made and the new docker image is built by the pipeline. When you forget to check the pipeline, your team members need to write you and ask you to deploy the new version.

As a solution, you want to **automate** this thing to save you and your team members time and energy.

<details>
<summary>Exercise 6: Add docker-compose for deployment</summary>
<br />

**Tasks:**

First:
- add docker-compose to your NodeJS application

The reason is you want to have the whole configuration for starting the docker container in a file, in case you need to make changes to that, instead of a plain docker command with parameters. Also, in case you add a database later.

Use repository: https://github.com/fsiegrist/devops-bootcamp-node-project

**Steps to solve the tasks:**\
**Step 1:** Add docker-compose.yaml\
Add a file called `docker-compose.yaml` with the following content to the root folder of the NodeJS project:
```sh
version: '3.9'
services:
    nodejs-app:
      image: fsiegrist/fesi-repo:devops-bootcamp-node-project-${IMAGE_TAG}
      ports:
        - 3000:3000
```

</details>

******

<details>
<summary>Exercise 7: Add "deploy to EC2" step to your pipeline</summary>
<br />

**Tasks:**

- Complete the pipeline of the exercises in the previous module 08 ("Build Automation & CI/CD with Jenkins") by adding a deployment step for your previous NodeJS project with docker-compose.

**Steps to solve the tasks:**\
**Step 1:** Create SSH credentials in Jenkins
- Login to the Jenkins management web console and install the "SSH Agent" plugin if it isn't already installed.
- Open "Dashboard" > "Manage Jenkins" > "Manage Credentials" and click on the domain "(global)" in the "Stores scoped to Jenkins" section.
- Press the "Add credentials" button.
- Select the kind "SSH Username with private key", enter the ID 'ec2-server-key', the username 'ec2-user', select "Private Key" > "Enter directly", press the "Add" button and paste the content of the `WebServerKeyPair.pem` file you downloaded from the EC2 server. (To copy the content on a mac without having to display it on the terminal, use `pbcopy < WebServerKeyPair.pem`.) Press the "Create" button.

**Step 2:** Open port 22 on EC2 server from Jenkins IP\
To allow Jenkins to ssh into the EC2 server, we have to add the IP address of the Jenkins host (64.225.104.226) to the firewall rule restricting access via port 22.
```sh
aws ec2 authorize-security-group-ingress \
  --group-id sg-0a6a9345d15c51f5e \
  --ip-permissions IpProtocol=tcp,FromPort=22,ToPort=22,IpRanges="[{CidrIp=64.225.104.226/32,Description='SSH access from Jenkins'}]"
```

**Step 3:** Login to Docker Hub\
To allow EC2 to pull a Docker image from our private repository on DockerHub, we have to login from EC2 to DockerHub once. This will create an entry in `/home/ec2-user/.docker/config.json` and keep the ec2-user logged in.
```sh
ssh -i WebServerKeyPair.pem ec2-user@3.122.205.189
docker login
  Username: fsiegrist
  Password: ***
  Login Succeeded
```

**Step 4:** Add deploy stage to Jenkinsfile\
Add the following snippets to the Jenkinsfile of the NodeJS project:
```groovy
pipeline {
    agent any

    parameters {
        booleanParam(name: 'deploy', defaultValue: false, description: 'Deploy the application on the EC2 server.') 
    }

    stages {
        ...
        stage('Build and Push Docker Image') {
            ...
        }
        stage('Deploy to EC2') {
            when {
                expression {
                    params.deploy
                }
            }
            steps {
                script {
                    echo 'deploying Docker image to EC2 server...'
                    
                    def dockerComposeCmd = "IMAGE_TAG=${IMAGE_VERSION} docker-compose up -d"
                    def ec2Instance = "ec2-user@3.122.205.189"

                    sshagent(['ec2-server-key']) {
                        sh "scp -o StrictHostKeyChecking=no docker-compose.yaml ${ec2Instance}:/home/ec2-user"
                        sh "ssh -o StrictHostKeyChecking=no ${ec2Instance} ${dockerComposeCmd}"
                    }
                }
            }
        }
        stage('Commit Version Update') {
            ...
        }
    }
}
```

Commit and push the changes to the repository. Switch to Jenkins and trigger the "node-project-pipeline". Trigger it a second time clicking on "Build with Parameters" and checking the "deploy" flag to include the new deploy stage.

Switch to the EC2 instance (ssh into it) and check with `docker ps` whether the nodejs-app container is running. 

</details>

******

<details>
<summary>Exercise 8: Configure access from browser (EC2 Security Group)</summary>
<br />

**Tasks:**

After executing the Jenkins pipeline successfully, the application is deployed, but you still can't access it from the browser. Again, you need to open the correct port on the server. For that you:
- Configure EC2 security group to access your application from browser (using AWS CLI)

**Steps to solve the tasks:**\
**Step 1:** Open port 3000 in security group to make app accessible from all IP addresses
```sh
aws ec2 authorize-security-group-ingress \
  --group-id sg-0a6a9345d15c51f5e \
  --protocol tcp \
  --port 3000 \
  --cidr 0.0.0.0/0
```

Now open a browser and navigate to [http://3.122.205.189:3000/](http://3.122.205.189:3000/) to see the application in action.

</details>

******

<details>
<summary>Exercise 9: Configure automatic triggering of multi-branch pipeline</summary>
<br />

**Tasks:**

Your team members are creating branches to add new features to the application or fix stuff, so you don't want to build and deploy all these half-done features or bug fixes. You want to build and deploy only the master branch. All other branches should only run tests. Add this logic to the Jenkinsfile.

- Add branch based logic to Jenkinsfile
- Add webhook to trigger pipeline automatically

**Steps to solve the tasks:**\
**Step 1:** Add branch based logic to Jenkinsfile\
Enhance the pipeline stages with a `when` expression evaluating the current branch:
```groovy
pipeline {
    agent any

    parameters {
        booleanParam(name: 'deploy', defaultValue: false, description: 'Deploy the application on the EC2 server.') 
    }

    stages {
        stage('Bump Version') {
            // only execute this stage for the master/main branch
            when {
                expression {
                    return env.GIT_BRANCH == "origin/main"
                }
            }
            steps {
                script {
                    bumpNpmVersion('app', 'patch')
                }
            }
        }
        stage('Run Tests') {
            // run the tests for every branch
            steps {
                script {
                    runNpmTests('app')
                }
            }
        }
        stage('Build and Push Docker Image') {
            // only execute this stage for the master/main branch
            when {
                expression {
                    return env.GIT_BRANCH == "origin/main"
                }
            }
            steps {
                buildAndPublishImage("fsiegrist/fesi-repo:devops-bootcamp-node-project-${IMAGE_VERSION}")
            }
        }
        stage('Deploy to EC2') {
            // only execute this stage for the master/main branch and if the respective flag is set
            when {
                expression {
                    return env.GIT_BRANCH == "origin/main" && params.deploy
                }
            }
            steps {
                ...
            }
        }
        stage('Commit Version Update') {
            // only execute this stage for the master/main branch
            when {
                expression {
                    return env.GIT_BRANCH == "origin/main"
                }
            }
            steps {
                ...
            }
        }
    }
}
```

**Step 2:** Add webhook to trigger pipeline automatically\
Since this is a simple pipeline project (not a multi-branch pipeline), we don't need a webhook. It is sufficient to do the following: Go to the Jenkins admin web console and open the pipeline project (`node-project-pipeline`), open the configuration and scroll down to the "Build Triggers" section. Check the "GitHub hook trigger for GITScm polling" checkbox and press the "Save" button.

</details>

******
